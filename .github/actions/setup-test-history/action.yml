name: 'Setup Test History and Baseline'
description: 'Downloads test history from S3 for smart reporter'

inputs:
  aws-access-key-id:
    description: 'AWS Access Key ID'
    required: true
  aws-secret-access-key:
    description: 'AWS Secret Access Key'
    required: true
  aws-region:
    description: 'AWS Region'
    required: true

runs:
  using: 'composite'
  steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ inputs.aws-access-key-id }}
        aws-secret-access-key: ${{ inputs.aws-secret-access-key }}
        aws-region: ${{ inputs.aws-region }}

    - name: Download test history from S3
      shell: bash
      run: |
        # Use branch-specific history files
        CLEAN_BRANCH=$(echo "${{ github.ref_name }}" | sed 's/[^a-zA-Z0-9._-]/_/g')
        echo "ðŸ” Looking for test-history files for branch: ${CLEAN_BRANCH}"

        # Download test-history files specific to this branch
        mkdir -p "history/${CLEAN_BRANCH}"
        aws s3 sync s3://kaleidos-qa-reports/history/${CLEAN_BRANCH}/ history/${CLEAN_BRANCH}/ --exclude "*" --include "test-history*" 2>/dev/null || echo "No test-history files found for branch ${CLEAN_BRANCH}"

        # Find and fix all test-history files for this branch
        HISTORY_FILES=()

        for file in history/${CLEAN_BRANCH}/test-history*.json; do
          if [ -f "$file" ]; then
            FILE_SIZE=$(wc -c < "$file")
            echo "ðŸ“„ Processing: $file (${FILE_SIZE} bytes)"
            
            # Debug: Show what's actually inside each file
            echo "   ðŸ” File content analysis:"
            node -e "
              try {
                const data = JSON.parse(require('fs').readFileSync('$file', 'utf8'));
                console.log('     Runs:', data.runs?.length || 0);
                console.log('     Tests:', Object.keys(data.tests || {}).length);
                console.log('     Summaries:', data.summaries?.length || 0);
                if (data.runs && data.runs.length > 0) {
                  const firstRun = data.runs[0];
                  console.log('     First run summary:', JSON.stringify(firstRun.summary || {}));
                  console.log('     First run ID:', firstRun.id || 'no-id');
                }
                if (Object.keys(data.tests || {}).length > 0) {
                  const testNames = Object.keys(data.tests).slice(0, 2);
                  console.log('     Sample tests:', testNames.join(', '));
                }
              } catch(e) {
                console.log('     âŒ Parse error:', e.message);
              }
            "
            
            # Add to files to analyze
            HISTORY_FILES+=("$file")
          fi
        done

        # Merge all history files into one
        if [ ${#HISTORY_FILES[@]} -gt 0 ]; then
          echo "ðŸ”— Analyzing and merging ${#HISTORY_FILES[@]} history files..."
          
          # First, let's see what we actually have
          echo "ðŸ“Š Content summary:"
          for file in "${HISTORY_FILES[@]}"; do
            echo "   ðŸ“„ $file"
          done
          
          node -e "
            const fs = require('fs');
            const mergedHistory = { runs: [], tests: {}, summaries: [] };
            
            const files = ['${HISTORY_FILES[*]}'].join(' ').split(' ');
            
            files.forEach(file => {
              if (!file) return;
              try {
                console.log('   ðŸ“„ Processing: ' + file);
                const data = JSON.parse(fs.readFileSync(file, 'utf8'));
                
                // Merge runs
                if (data.runs) {
                  mergedHistory.runs.push(...data.runs);
                }
                
                // Merge tests
                if (data.tests) {
                  Object.assign(mergedHistory.tests, data.tests);
                }
                
                // Merge summaries
                if (data.summaries) {
                  mergedHistory.summaries.push(...data.summaries);
                }
              } catch(e) {
                console.log('   âŒ Error reading ' + file + ': ' + e.message);
              }
            });
            
            // Remove duplicate runs by ID
            const uniqueRuns = {};
            mergedHistory.runs.forEach(run => {
              if (run.id) uniqueRuns[run.id] = run;
            });
            mergedHistory.runs = Object.values(uniqueRuns);
            
            // Remove duplicate summaries by runId
            const uniqueSummaries = {};
            mergedHistory.summaries.forEach(summary => {
              if (summary.runId) uniqueSummaries[summary.runId] = summary;
            });
            mergedHistory.summaries = Object.values(uniqueSummaries);
            
            fs.writeFileSync('test-history.json', JSON.stringify(mergedHistory, null, 2));
            console.log('âœ… Merged ' + mergedHistory.runs.length + ' unique runs from ' + files.length + ' files');
          "
        fi

        if [ ${#HISTORY_FILES[@]} -gt 0 ]; then
          echo "ðŸ“Š Unified history loaded with multiple runs for branch: ${CLEAN_BRANCH}"
          
          # Extract the most recent run ID from merged history for baseline
          BASELINE_RUN_ID=$(node -pe 'try { 
            const history = JSON.parse(require("fs").readFileSync("test-history.json", "utf8")); 
            const runs = history.runs || []; 
            runs.length > 0 ? runs[runs.length - 1].id || runs[0].id : "" 
          } catch(e) { "" }')
          
          if [ -n "$BASELINE_RUN_ID" ]; then
            echo "BASELINE_RUN_ID=${BASELINE_RUN_ID}" >> $GITHUB_ENV
            echo "ðŸŽ¯ Baseline Run ID set to: ${BASELINE_RUN_ID}"
          else
            echo "âš ï¸ Could not extract baseline run ID from merged history"
          fi
        else
          echo "â„¹ï¸ No test-history files found for branch ${CLEAN_BRANCH}, smart reporter will start fresh"
        fi

        # CLEANUP: After analyzing, delete all existing history data to start fresh
        echo ""
        echo "ðŸ§¹ Analysis complete - now cleaning up all existing history data in S3 for fresh start..."

        # Delete main history file
        aws s3 rm s3://kaleidos-qa-reports/test-history.json 2>/dev/null || echo "No main history file to delete"

        # Delete all branch history files
        echo "ðŸ—‘ï¸ Deleting all branch history folders..."
        aws s3 rm s3://kaleidos-qa-reports/history/ --recursive 2>/dev/null || echo "No history folders to delete"

        # Delete any other test-related JSON files
        echo "ðŸ—‘ï¸ Deleting any other test-related JSON files..."
        aws s3 ls s3://kaleidos-qa-reports/ --recursive | grep "\.json$" | while read -r line; do
          # Extract the file path from the ls output (skip date/time/size columns)
          file_path=$(echo "$line" | awk '{print $4}')
          if [[ "$file_path" == *"test"* || "$file_path" == *"history"* || "$file_path" == *"result"* ]]; then
            echo "ðŸ—‘ï¸ Deleting: $file_path"
            aws s3 rm "s3://kaleidos-qa-reports/$file_path" 2>/dev/null || true
          fi
        done

        echo "âœ… S3 cleanup completed - smart reporter will start with clean slate"

        # Remove local test-history.json if it was created
        rm -f test-history.json
        echo "ðŸ§¹ Local cleanup completed"
